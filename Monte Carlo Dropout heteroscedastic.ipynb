{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1810b555-1845-48d6-a564-03823d54b294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.5275275707244873\n",
      "Epoch 100, Loss: -2.393179416656494\n",
      "Epoch 200, Loss: -3.018993616104126\n",
      "Epoch 300, Loss: -3.18143892288208\n",
      "Epoch 400, Loss: -3.2241427898406982\n",
      "Epoch 500, Loss: -3.361675262451172\n",
      "Epoch 600, Loss: -3.3818888664245605\n",
      "Epoch 700, Loss: -3.47339129447937\n",
      "Epoch 800, Loss: -3.4801342487335205\n",
      "Epoch 900, Loss: -3.4428200721740723\n",
      "Normalized Predictions: [1.4267138242721558, 1.3200623989105225, 1.2083367109298706, 1.1118072271347046, 0.9836230278015137, 0.9049385786056519, 0.8061133623123169, 0.7096899747848511, 0.615459680557251, 0.5171676874160767]\n",
      "Denormalized Predictions: [18532.845875828658, 18470.422082336365, 18405.028288951613, 18348.528935643255, 18273.501865343747, 18227.447330291805, 18169.604269378106, 18113.16701492574, 18058.0133926686, 18000.482430836768]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import oandapyV20\n",
    "import oandapyV20.endpoints.instruments as instruments\n",
    "\n",
    "# Define parameters for the OANDA API\n",
    "access_token = \"e11aadc917842adf254cd73c038c4e0a-321ea21ac5697ab46036807f5e5e943d\"\n",
    "instrument = \"NAS100_USD\"\n",
    "\n",
    "# Fetch data from OANDA API\n",
    "api = oandapyV20.API(access_token=access_token)\n",
    "\n",
    "params = {\n",
    "    \"count\": 5000,\n",
    "    \"granularity\": \"M30\"\n",
    "}\n",
    "\n",
    "r = instruments.InstrumentsCandles(instrument=instrument, params=params)\n",
    "data = []\n",
    "\n",
    "while True:\n",
    "    response = api.request(r)\n",
    "    data.extend(response[\"candles\"])\n",
    "    if \"next\" not in response:\n",
    "        break\n",
    "    r.params[\"from\"] = response[\"next\"]\n",
    "\n",
    "# Extracting close prices from candles\n",
    "time_series_data = [float(candle[\"mid\"][\"c\"]) for candle in data]\n",
    "\n",
    "# Normalizing the data\n",
    "mean = np.mean(time_series_data)\n",
    "std = np.std(time_series_data)\n",
    "normalized_data = (time_series_data - mean) / std\n",
    "\n",
    "# Function to create dataset for training\n",
    "def create_dataset(data, window_size):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        x.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    x = np.array(x).reshape(-1, window_size, 1)\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "    return x, y\n",
    "\n",
    "# Define window size and create dataset\n",
    "window_size = 20  # Number of previous time steps to use as input\n",
    "x_data, y_data = create_dataset(normalized_data, window_size)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_data, dtype=torch.float32)\n",
    "\n",
    "# Define the model\n",
    "class MonteCarloDropoutModel(nn.Module):\n",
    "    def __init__(self, loss_type=\"heteroscedastic\"):\n",
    "        super(MonteCarloDropoutModel, self).__init__()\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "        self.fc1 = nn.Linear(window_size, 100)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.mean_layer = nn.Linear(100, 1)\n",
    "        if self.loss_type == \"heteroscedastic\":\n",
    "            self.var_layer = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        mean = self.mean_layer(x)\n",
    "        if self.loss_type == \"heteroscedastic\":\n",
    "            log_var = self.var_layer(x)\n",
    "            return mean, log_var\n",
    "\n",
    "        return mean\n",
    "\n",
    "# Define the loss functions\n",
    "def mse_loss(model, x, y_true):\n",
    "    y_pred = model(x)\n",
    "    mse = F.mse_loss(y_pred, y_true)\n",
    "    return mse\n",
    "\n",
    "def heteroscedastic_loss(model, x, y_true):\n",
    "    mean, log_var = model(x)\n",
    "    precision = torch.exp(-log_var)\n",
    "    mse = torch.mean(0.5 * precision * (y_true - mean)**2 + log_var)\n",
    "    return mse\n",
    "\n",
    "# Training function\n",
    "def fit_model(model, x_train, y_train, epochs, learning_rate, loss_type):\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if loss_type == \"mse\":\n",
    "            loss = mse_loss(model, x_train, y_train)\n",
    "        elif loss_type == \"heteroscedastic\":\n",
    "            loss = heteroscedastic_loss(model, x_train, y_train)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# Define the model and train it\n",
    "model = MonteCarloDropoutModel(loss_type=\"heteroscedastic\")\n",
    "fit_model(model, x_train, y_train, epochs=1000, learning_rate=0.001, loss_type=\"heteroscedastic\")\n",
    "\n",
    "# Function to perform multi-step forecasting\n",
    "def multi_step_forecast(model, initial_data, steps, window_size):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    current_data = initial_data[-window_size:]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(steps):\n",
    "            input_tensor = torch.tensor(current_data.reshape(1, -1, 1), dtype=torch.float32)\n",
    "            mean, _ = model(input_tensor)\n",
    "            mean = mean.item()\n",
    "\n",
    "            predictions.append(mean)\n",
    "            current_data = np.append(current_data[1:], mean)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Perform a multi-step forecast\n",
    "steps = 10  # Number of steps to forecast\n",
    "initial_data = normalized_data[-window_size:]  # Last `window_size` points of the normalized data\n",
    "predictions = multi_step_forecast(model, initial_data, steps, window_size)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Normalized Predictions:\", predictions)\n",
    "\n",
    "# Optionally, denormalize the predictions\n",
    "denormalized_predictions = [pred * std + mean for pred in predictions]\n",
    "print(\"Denormalized Predictions:\", denormalized_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db697e-f734-477c-9b6f-12c67bd162ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
